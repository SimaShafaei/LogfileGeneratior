{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,index, name, mean, std):\n",
    "        self.index = index\n",
    "        self.name = name\n",
    "        self.prior_mean = np.copy(mean)\n",
    "        self.prior_std = np.copy(std)\n",
    "        self.posterior_mean=0\n",
    "        self.posterior_std=0\n",
    "        self.value = None\n",
    "        self.parents = []\n",
    "        self.children = []        \n",
    "\n",
    "    def add_parent(self, parent):\n",
    "        self.parents.append(parent)        \n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class BayesNet:\n",
    "    def __init__(self,num_nodes):\n",
    "        # num_nodes = number of nodes (int)\n",
    "        self.num_nodes=num_nodes\n",
    "        \n",
    "        #dictionary of names and index of nodes\n",
    "        self.names_index={}\n",
    "        \n",
    "        # structure = shows the structre of BN,(matrix) \n",
    "        self.structure=np.empty((num_nodes, num_nodes))\n",
    "        \n",
    "        self.weights=np.empty((num_nodes, num_nodes))\n",
    "        \n",
    "        # the parameters of nodes, \n",
    "        self.params=[]\n",
    "                \n",
    "        # the bserved node and their values and array of tuple (node, value)\n",
    "        #self.observed_nodes=[]\n",
    "        \n",
    "        # an array that determines the order of nodes for elimination\n",
    "        self.orders=[]\n",
    "        \n",
    "        #set Nodes\n",
    "        self.nodes=[]\n",
    "        for i in range(num_nodes):\n",
    "            self.nodes.append(Node(i,\"\", mean=[], std=[]))\n",
    "    \n",
    "    #Set names of all nodes\n",
    "    def set_node_names(self,node_names): \n",
    "        self.names_index={}\n",
    "        for i in range(self.num_nodes):\n",
    "            self.nodes[i].name = node_names[i] \n",
    "            self.names_index[node_names[i]]=i\n",
    "        return\n",
    "    \n",
    "    # Set prior destribution of all nodes\n",
    "    def set_priors(self, node_prior):\n",
    "        for i in range(self.num_nodes):\n",
    "            self.nodes[i].prior_mean =np.copy(node_prior[i]['mean'])  \n",
    "            self.nodes[i].prior_std=np.copy(node_prior[i]['std'])\n",
    "        return \n",
    "    \n",
    "    # Set prior destribution of node i\n",
    "    # the prior of nodes,  it is an array of ([mu1,...,muk],[sgma1, ..., sigmak]) with size num_nodes for a Gaussian mixture model\n",
    "    def set_prior(self,node_prior,i):\n",
    "        self.nodes[i].mean =np.copy(node_prior['mean'])\n",
    "        self.nodes[i].std=np.copy(node_prior['std'])\n",
    "        return\n",
    "    \n",
    "    # Set values of nodes with nodeIndexs (Set all observed_nodes or evidence)\n",
    "    def set_values(self, assignmens):\n",
    "        for name,value in assignmens.items():\n",
    "            self.nodes[self.names_index[name]].value =value\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def set_structure(self, struct):\n",
    "        self.structure=np.copy(struct)  \n",
    "        \n",
    "        # Establish parent-child relationships based on the adjacency matrix\n",
    "        for i in range(self.num_nodes):\n",
    "            for j in range(self.num_nodes):\n",
    "                if struct[i][j] == 1:\n",
    "                    self.nodes[i].add_child(self.nodes[j])\n",
    "                    self.nodes[j].add_parent(self.nodes[i])        \n",
    "        return\n",
    "    \n",
    "    def add_edge(self,parent_name,child_name,weight):\n",
    "        parent_index=self.names_index[parent_name]\n",
    "        child_index=self.names_index[child_name]\n",
    "        self.structure[parent_index][child_index]=1\n",
    "        self.nodes[parent_index].add_child(self.nodes[child_index])\n",
    "        self.nodes[child_index].add_parent(self.nodes[parent_index])\n",
    "        self.params[parent_index][child_index]=weight\n",
    "        \n",
    "    #set Parameters or weights of netword\n",
    "    def set_params(self, parameters): \n",
    "        self.params= np.copy(parameters)\n",
    "        return\n",
    "\n",
    "    def set_num_node(self, n):\n",
    "        self.num_node=n\n",
    "        return\n",
    "    \n",
    "    def get_structure(self):\n",
    "        return self.structure    \n",
    "           \n",
    "    def get_num_node(self):\n",
    "        return self.num_nodes\n",
    "        \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "        \n",
    "    def _get_topological_order(self):\n",
    "        orders=[]\n",
    "        nodes=[i for i in range(self.num_nodes)]\n",
    "        bn_struct=np.copy(struct)\n",
    "                \n",
    "        while len(nodes)>0 : \n",
    "            \n",
    "            # Determine the nodes that are in the highest order (zero columns means they have no parent)\n",
    "            zero_columns = np.all(bn_struct == 0, axis=0)\n",
    "\n",
    "            # Add nodes to orders                      \n",
    "            for i in range(len(zero_columns)):\n",
    "                if zero_columns[i]:\n",
    "                    orders.append(nodes[i])\n",
    "\n",
    "            # Remove their columns and rows from bn_struct\n",
    "            bn_struct=bn_struct[~zero_columns][:, ~zero_columns]\n",
    "           \n",
    "            # Remove orderd nodes from nodes\n",
    "            nodes = [node for node, zero_col in zip(nodes, zero_columns) if not zero_col]\n",
    "            \n",
    "        self.orders=orders    \n",
    "        return orders\n",
    "    \n",
    "    def save_to_file(self):\n",
    "        df = pd.DataFrame(self.params, index=node_names, columns=node_names)\n",
    "    \n",
    "    # Calculate additional features (mean and std) for each node\n",
    "    node_mean = np.mean(matrix, axis=1)\n",
    "    node_std = np.std(matrix, axis=1)\n",
    "    \n",
    "    # Add the additional features as new columns\n",
    "    df['Mean'] = node_mean\n",
    "    df['Std'] = node_std\n",
    "    \n",
    "    df.to_csv('graph.csv')\n",
    "    def get_posteriors(self):\n",
    "        posteriors={}\n",
    "        for node in self.nodes:\n",
    "            posteriors[node.name]=[node.posterior_mean,node.posterior_std]\n",
    "        return posteriors\n",
    "       \n",
    "    def perform_inference(self,query_nodes):\n",
    "        #Get topological order for eleminating variables\n",
    "        self._get_topological_order()\n",
    "            \n",
    "        for i in self.orders:\n",
    "            node=self.nodes[i] \n",
    "            \n",
    "            # Update posterior for Observed Nodes or Evidences\n",
    "            if node.value is not None:\n",
    "                node.posterior_mean=np.array([node.value])                \n",
    "                node.posterior_std=np.array([0.001])   # Set to 0.001 to avoid devision by zero\n",
    "                \n",
    "            \n",
    "            else:\n",
    "                # Get mean and std of prior distribution of current node \n",
    "                mean, precision = node.prior_mean, (1.0 / (node.prior_std ** 2))\n",
    "                mean = mean* precision\n",
    "                \n",
    "                # Obtained posterior mean and std based on posterior destribution of parents and weights.\n",
    "                sum_weights=1\n",
    "                precision_sum = precision\n",
    "                for i, parent in enumerate(node.parents):\n",
    "                    weight = self.params[parent.index][node.index]            \n",
    "                    precision = 1.0 / (parent.posterior_std ** 2)\n",
    "                    precision_sum = precision_sum + (weight ** 2) * precision\n",
    "                    mean = mean + (weight ** 2) * parent.posterior_mean * precision         \n",
    "                node.posterior_mean=mean/precision_sum\n",
    "                node.posterior_std = np.sqrt(1 / precision_sum)\n",
    "        \n",
    "        result=[] \n",
    "        for n in query_nodes:\n",
    "            i=self.names_index[n]\n",
    "            result.append(np.random.normal(self.nodes[i].posterior_mean[0], self.nodes[i].posterior_std[0]))\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Define the node names\n",
    "node_names=[\"Flexibility\", \n",
    "           \"UserExperience\",\n",
    "           \"Adaptability\",\n",
    "           \"Legibility\",\n",
    "           \"GroupingByFormat\",\n",
    "           \"GroupingByLocation\",\n",
    "           \"Grouping\",\n",
    "           \"SignificanceOfCodes\",\n",
    "           \"TimeGaps\",\n",
    "           \"NumberOfUse\",\n",
    "           \"Consistency\",\n",
    "           \"ImmediateFeedback\",\n",
    "           \"ExplicitUserAction\",\n",
    "           \"UserControl\",\n",
    "           \"ExplicitControl\",\n",
    "           \"Prompting\",\n",
    "           \"ErrorProtection\",\n",
    "           \"ErrorCorrection\",\n",
    "           \"QualityOfErrorMessage\",\n",
    "           \"ErrorManagement\",\n",
    "           \"InformationDensity\",\n",
    "           \"MinimalAction\",\n",
    "           \"Conciseness\",\n",
    "           \"Brevity\",\n",
    "           \"Remembering\",\n",
    "           \"Learning\",\n",
    "           \"CorrectPath\",\n",
    "           \"Time\",\n",
    "           \"Back\",\n",
    "           \"LoopOnTheSamePage\",\n",
    "           \"WrongPath\",\n",
    "           \"Incomplete\"]\n",
    "# Determine number of nodes, and create empty structure and parameter \n",
    "n_nodes=len(node_names)\n",
    "struct=np.zeros((n_nodes,n_nodes))\n",
    "params=np.zeros((n_nodes,n_nodes))\n",
    "\n",
    "# create empty BN for determined nodes\n",
    "bn=BayesNet(n_nodes)\n",
    "bn.set_structure(struct)\n",
    "bn.set_node_names(node_names)\n",
    "bn.set_params(params)\n",
    "\n",
    "#Add Edges and Parameters to BN\n",
    "bn.add_edge(\"Flexibility\",\"Adaptability\",1)\n",
    "bn.add_edge(\"UserExperience\",\"Adaptability\",1)\n",
    "bn.add_edge(\"Adaptability\",\"Remembering\",1)\n",
    "bn.add_edge(\"Adaptability\",\"Learning\",1)\n",
    "bn.add_edge(\"Adaptability\",\"Time\",1)\n",
    "bn.add_edge(\"Adaptability\",\"CorrectPath\",1)\n",
    "\n",
    "bn.add_edge(\"Legibility\",\"Time\",1)\n",
    "\n",
    "bn.add_edge(\"GroupingByFormat\",\"Grouping\",1)\n",
    "bn.add_edge(\"GroupingByLocation\",\"Grouping\",1)\n",
    "bn.add_edge(\"Grouping\",\"Remembering\",1)\n",
    "bn.add_edge(\"Grouping\",\"Learning\",1)\n",
    "bn.add_edge(\"Grouping\",\"Time\",1)\n",
    "bn.add_edge(\"Grouping\",\"CorrectPath\",1)\n",
    "\n",
    "bn.add_edge(\"SignificanceOfCodes\",\"Remembering\",1)\n",
    "bn.add_edge(\"SignificanceOfCodes\",\"CorrectPath\",1)\n",
    "\n",
    "bn.add_edge(\"TimeGaps\",\"Remembering\",1)\n",
    "\n",
    "bn.add_edge(\"NumberOfUse\",\"Remembering\",1)\n",
    "bn.add_edge(\"NumberOfUse\",\"Learning\",1)\n",
    "\n",
    "bn.add_edge(\"Consistency\",\"Remembering\",1)\n",
    "bn.add_edge(\"Consistency\",\"Learning\",1)\n",
    "bn.add_edge(\"Consistency\",\"Time\",1)\n",
    "bn.add_edge(\"Consistency\",\"CorrectPath\",1)\n",
    "\n",
    "bn.add_edge(\"ImmediateFeedback\",\"CorrectPath\",1)\n",
    "\n",
    "bn.add_edge(\"ExplicitUserAction\",\"ExplicitControl\",1)\n",
    "bn.add_edge(\"UserControl\",\"ExplicitControl\",1)\n",
    "bn.add_edge(\"ExplicitControl\",\"Learning\",1)\n",
    "\n",
    "bn.add_edge(\"Prompting\",\"Remembering\",1)\n",
    "bn.add_edge(\"Prompting\",\"Learning\",1)\n",
    "bn.add_edge(\"Prompting\",\"Back\",1)\n",
    "bn.add_edge(\"Prompting\",\"LoopOnTheSamePage\",1)\n",
    "bn.add_edge(\"Prompting\",\"WrongPath\",1)\n",
    "\n",
    "bn.add_edge(\"ErrorProtection\",\"ErrorManagement\",1)\n",
    "bn.add_edge(\"ErrorCorrection\",\"ErrorManagement\",1)\n",
    "bn.add_edge(\"QualityOfErrorMessage\",\"ErrorManagement\",1)\n",
    "bn.add_edge(\"ErrorManagement\",\"Incomplete\",1)\n",
    "bn.add_edge(\"ErrorManagement\",\"WrongPath\",1)\n",
    "bn.add_edge(\"ErrorManagement\",\"Learning\",1)\n",
    "bn.add_edge(\"ErrorManagement\",\"Time\",1)\n",
    "\n",
    "bn.add_edge(\"InformationDensity\",\"Incomplete\",1)\n",
    "bn.add_edge(\"InformationDensity\",\"WrongPath\",1)\n",
    "bn.add_edge(\"InformationDensity\",\"Learning\",1)\n",
    "\n",
    "bn.add_edge(\"MinimalAction\",\"Brevity\",1)\n",
    "bn.add_edge(\"Conciseness\",\"Brevity\",1)\n",
    "bn.add_edge(\"Brevity\",\"Learning\",1)\n",
    "bn.add_edge(\"Brevity\",\"Remembering\",1)\n",
    "bn.add_edge(\"Brevity\",\"Time\",1)\n",
    "bn.add_edge(\"Brevity\",\"LoopOnTheSamePage\",1)\n",
    "bn.add_edge(\"Brevity\",\"Incomplete\",1)\n",
    "\n",
    "bn.add_edge(\"Remembering\",\"Time\",1)\n",
    "bn.add_edge(\"Remembering\",\"CorrectPath\",1)\n",
    "\n",
    "bn.add_edge(\"Learning\",\"Time\",1)\n",
    "bn.add_edge(\"Learning\",\"CorrectPath\",1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Prior distributions of all nodes\n",
    "Legibility: 0, m= 80,100\n",
    "Grouping: 50\n",
    "Immediate feedback: 60\n",
    "Prompting: 40\n",
    "Remembering: 50\n",
    "Learning: 50\n",
    "Time: 0.1 -  5 – 20\n",
    "Correct Path:45\n",
    "Back:20\n",
    "Loop:20\n",
    "Wrong:10\n",
    "Incomplete: 5\n",
    "\n",
    "Information Density:50 , std high\n",
    "Brevity: 50\n",
    "Explicit control: 50 std m\n",
    "Flexibility\n",
    "User Experience:\n",
    "Adaptability: 50\n",
    "Error Protection:\n",
    "Quality:\n",
    "Error Correction:\n",
    "Error Management: 50\n",
    "Significance of Code: 45\n",
    "Consistency: 40\n",
    "\n",
    "prior=[]\n",
    "for i in range(5):\n",
    "    prior.append({\"mean\":m[i], \"std\":s[i]})\n",
    "querynodes=[\"E\",\"D\"]\n",
    "bn.set_priors(prior)\n",
    "\n",
    "# Set Evidence\n",
    "evidences={\"A\":10}\n",
    "bn.set_values(evidences)\n",
    "\n",
    "#perform inference to obtain posterior distributions\n",
    "bn.perform_inference(querynodes)\n",
    "print(bn.get_posteriors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59715871] [0.11757092]\n",
      "[0.59778997] [0.42093245]\n",
      "[0.67851986] [0.92372933]\n",
      "[0.84174378] [0.43820858]\n",
      "[0.6720609] [0.42274467]\n",
      "{'A': [array([10]), array([0.001])], 'B': [array([9.99999788]), array([0.0002])], 'C': [array([9.99999956]), array([0.0002])], 'D': [array([9.99999868]), array([2.82842693e-05])], 'E': [array([9.99999779]), array([3.99999953e-05])]}\n"
     ]
    }
   ],
   "source": [
    "struct= [[0,1,1,0,0],\n",
    "         [0,0,0,1,1],\n",
    "         [0,0,0,1,0],\n",
    "         [0,0,0,0,0],\n",
    "         [0,0,0,0,0]]\n",
    "\n",
    "params = [[0,5,5,0,0],\n",
    "         [0,0,0,5,5],\n",
    "         [0,0,0,5,0],\n",
    "         [0,0,0,0,0],\n",
    "         [0,0,0,0,0]]\n",
    "\n",
    "bn=BayesNet(5)\n",
    "bn.set_structure(struct)\n",
    "bn.set_node_names([\"A\",\"B\",\"C\",\"D\",\"E\"])\n",
    "\n",
    "prior=[]\n",
    "for i in range(5):\n",
    "    m=np.random.rand(1)\n",
    "    s=np.random.rand(1)\n",
    "    prior.append({\"mean\":m, \"std\":s})\n",
    "\n",
    "\n",
    "bn.set_priors(prior)\n",
    "for node in bn.nodes:\n",
    "    print(node.prior_mean, node.prior_std)\n",
    "    \n",
    "\n",
    "    \n",
    "bn.set_values({\"A\":10})\n",
    "\n",
    "\n",
    "bn.set_params(params)\n",
    "querynodes=[\"E\",\"D\"]\n",
    "bn.perform_inference(querynodes)\n",
    "print(bn.get_posteriors())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(node):\n",
    "        #evidence = []\n",
    "        #for parent in node.parents:\n",
    "        #    evidence.append(forward_pass(parent))\n",
    "\n",
    "        mean, precision = node.mean, (1.0 / (node.std ** 2))\n",
    "        mean = mean* precision\n",
    "        # update mean and std based on obtained evidence for parents.\n",
    "        sum_weights=1\n",
    "        precision_sum = precision\n",
    "        for i, parent in enumerate(node.parents):\n",
    "            weight = self.params[parent.index][node.index]            \n",
    "            precision = 1 / (parent.std ** 2)\n",
    "            precision_sum = precision_sum + (weight ** 2) * precision\n",
    "            mean = mean + (weight ** 2) * parent.mean * precision \n",
    "        \n",
    "        mean=mean/precision_sum\n",
    "        std = np.sqrt(1 / precision_sum)\n",
    "           \n",
    "        \n",
    "        # set random value for the node \n",
    "        node.set_value(np.random.normal(mean, np.sqrt(1.0 / std)))\n",
    "\n",
    "        return node.value\n",
    "\n",
    "def update_node_with_evidence(self,node, evidence_value):\n",
    "    node.mean = evidence_value\n",
    "    node.std = 0.0  # Set standard deviation to 0 for a point distribution\n",
    "    return node"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
