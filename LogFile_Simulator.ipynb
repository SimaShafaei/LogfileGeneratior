{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Log File Generator\n",
    "\n",
    "This program will generate a synthetic log file \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Related to Random Number Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import truncnorm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a group of random number with size count\n",
    "def randints(count , *randint_args):\n",
    "    ri= partial(random.randint, *randint_args)\n",
    "    return [ri() for _ in range(count)]\n",
    "\n",
    "\n",
    "# Get the cdf (cumulative distribution function) of n event and select one of them based on their probabilities\n",
    "def random_item_selection(cdf):\n",
    "    x = random.uniform(0, 1)\n",
    "    i=0\n",
    "    while i<len(cdf):\n",
    "        if cdf[i]>x:\n",
    "            break\n",
    "        i+=1\n",
    "    return i\n",
    "        \n",
    "\n",
    "# Create a random integer number based on a guassian mixture distribution \n",
    "#  - gaussian_selection_probability determines the probability of selection each gaussian distribution\n",
    "#  - mu and sd are array of means and standard deviation of each gaussian distribution\n",
    "#  - positive is a True/False value which determines if the result should be positive or not\n",
    "def gaussian_mixture_randint(mu,sd,gaussian_selection_probability,positive):\n",
    "    i=random_item_selection(gaussian_selection_probability)    \n",
    "    result= int(np.random.normal(mu[i], sd[i]))\n",
    "    \n",
    "    if positive and result<=0:\n",
    "        return 1\n",
    "    else:    \n",
    "        return result\n",
    "    \n",
    "# Assign probability to n different variable (satisfying sum-to-one and positivity condition) and return the cdf \n",
    "def random_probablity(n):\n",
    "    list_of_random_float=np.random.random(n)\n",
    "    sum_value=list_of_random_float.sum()\n",
    "    normalized_values=list_of_random_float/sum_value\n",
    "    for i in range(1,len(normalized_values)):\n",
    "        normalized_values[i]=normalized_values[i]+normalized_values[i-1]\n",
    "    return normalized_values\n",
    "\n",
    " \n",
    "def truncated_normal_rand(mu,sd,a,b):\n",
    "    # Calculate the normalized lower and upper bounds\n",
    "    lower = (a - mu) / sd\n",
    "    upper = (b - mu) / sd\n",
    "\n",
    "    # Generate a random variable based on truncated normal distribution\n",
    "    random_var = truncnorm.rvs(lower, upper, loc=mu, scale=sd)\n",
    "    \n",
    "    return random_var\n",
    "\n",
    "def plot_truncated_normal(mu,sd,a,b,plt_title):\n",
    "    # Calculate the normalized lower and upper bounds\n",
    "    lower = (a - mu) / sd\n",
    "    upper = (b - mu) / sd \n",
    "    \n",
    "    # Create a truncated normal distribution object\n",
    "    dist = truncnorm(lower, upper, loc=mu, scale=sd)\n",
    "\n",
    "    # Generate a range of x values to plot\n",
    "    x = np.linspace(a, b, 100)\n",
    "\n",
    "    # Plot the truncated normal distribution\n",
    "    plt.plot(x, dist.pdf(x))\n",
    "\n",
    "    # Add axis labels and a title to the plot\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('PDF')\n",
    "    plt.title(plt_title)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Pages Usability Features and Average Completion Time Assignment\n",
    "Assign usability features randomly to each page in the sitemap, based on their predetermined distributions.\n",
    "- In this program time unit is hour \n",
    "- For usability feature a truncate normal distribution will be used that for most of them the value of variable is truncated between 0 and 100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_of_usability_feature():\n",
    "    plot_truncated_normal(50,10,0,100,'FLEXIBILITY')\n",
    "    plot_truncated_normal(50,10,0,100,'USER EXPERIENCE')\n",
    "    plot_truncated_normal(70,10,0,100,'LEGIBILITY')\n",
    "    plot_truncated_normal(45,10,0,100,'GROUPING BY FORMAT')\n",
    "    plot_truncated_normal(75,10,0,100,'GROUPING BY LOCATION')\n",
    "    plot_truncated_normal(50,10,0,100,'SIGNIFICANCE OF CODE')\n",
    "    plot_truncated_normal(60,10,0,100,'CONSISTENCY')\n",
    "    plot_truncated_normal(50,10,0,100,'IMMEDIATE FEEDBACK')\n",
    "    plot_truncated_normal(60,10,0,100,'EXPLICIT USER ACTION')\n",
    "    plot_truncated_normal(80,10,0,100,'USER CONTROL')\n",
    "    plot_truncated_normal(80,10,0,100,'PROMPTING')\n",
    "    plot_truncated_normal(80,10,0,100,'ERROR PROTECTION')\n",
    "    plot_truncated_normal(90,10,0,100,'QUALITY OF ERROR MESSAGE') \n",
    "    plot_truncated_normal(80,10,0,100,'ERROR CORRECTION')\n",
    "    plot_truncated_normal(50,20,0,100,'INFORMATION DENSITY')\n",
    "    plot_truncated_normal(75,10,0,100,'MINIMAL ACTION')\n",
    "    plot_truncated_normal(80,10,0,100,'CONCISENESS')\n",
    "    plot_truncated_normal(3,5,1,20,'Time')\n",
    "\n",
    "def assign_page_featurs():\n",
    "\n",
    "    #Random variable assignment for each variable in the highest level of BN \n",
    "    \n",
    "    flexibility = truncated_normal_rand(50,10,0,100)\n",
    "    user_experience = truncated_normal_rand(50,10,0,100)\n",
    "    legibility = truncated_normal_rand(70,10,0,100)\n",
    "    grouping_by_format = truncated_normal_rand(45,10,0,100)\n",
    "    grouping_by_location = truncated_normal_rand(75,10,0,100)\n",
    "    significance_of_code = truncated_normal_rand(50,10,0,100)\n",
    "    consistency = truncated_normal_rand(60,10,0,100)\n",
    "    immediate_feedback = truncated_normal_rand(50,10,0,100)\n",
    "    explicit_user_action = truncated_normal_rand(60,10,0,100)\n",
    "    user_control = truncated_normal_rand(80,10,0,100)\n",
    "    prompting  = truncated_normal_rand(80,10,0,100)\n",
    "    error_protection  = truncated_normal_rand(80,10,0,100)\n",
    "    quality_of_error_message  = truncated_normal_rand(90,10,0,100)\n",
    "    error_correction  = truncated_normal_rand(80,10,0,100)\n",
    "    information_density  = truncated_normal_rand(50,20,0,100)\n",
    "    minimal_action  = truncated_normal_rand(75,10,0,100)\n",
    "    conciseness  = truncated_normal_rand(80,10,0,100)\n",
    "    time = truncated_normal_rand(3,5,1,20)*0.016\n",
    "    \n",
    "    page_features=[flexibility,user_experience,legibility,grouping_by_format,grouping_by_location,significance_of_code,\n",
    "                   consistency,immediate_feedback,explicit_user_action,user_control,prompting,error_protection,\n",
    "                   quality_of_error_message,error_correction,information_density,minimal_action,conciseness,time]\n",
    "    return page_features\n",
    "\n",
    "\n",
    "def setup_website_featurs(pageList):\n",
    "    web_feature={}\n",
    "    for p in pageList:\n",
    "        web_feature[p]=assign_page_featurs()\n",
    "    return web_feature\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuction for determining wrong path\n",
    "This functions determine the wrong path should be added to the path if an incorrect path is selected by user.\n",
    "visited_wrong_pages will takes the structure of website, current page and the corrected page and will go through a wong path if there is any and continue this path until it finally halt or back to the correct path. \n",
    "\n",
    "- The probability of halt will increased based on the length of the path in wrong direction and based on usability features of web page.\n",
    "\n",
    "- The probability of back to the correct page will impacted based on the length of path in wrong direction and usability features of web page.\n",
    "\n",
    "- The probability of continueing wrong path or halting will decrease based on users' history of usage.\n",
    "\n",
    "The function action_in_wrong_path will determine the if it should continue the wrong path. back to the previous page or halt based on the above features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2781841427.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\sshaf\\AppData\\Local\\Temp\\ipykernel_15400\\2781841427.py\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    page =#select a page that follows sourcepage and is not correct page\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def action_probability_in_wrong_path(page, path_len, user):\n",
    "    # path_len: toole masiri ast ke dar masir eshtebah tey shode.\n",
    "    \n",
    "    # baraye nazdiki be vagheiat bayad ehtemal ra tori dar nazar begirim ke ba afzayeshe toole masir ehtemal halt afzayes peyda konad \n",
    "    # dar avaye masir ehtemal back bishtar bashad\n",
    "        # r=select a random uniform number\n",
    "        # if r <1/3 :\n",
    "        #    state =\"continueError\"\n",
    "        # elif r<2/3\n",
    "        #    state = \"backToCorrect\"\n",
    "        # else \n",
    "        # state= \"halt\"\n",
    "    return state\n",
    "\n",
    "def visited_wrong_pages(sitemap,sourcepage,correctpage, user):\n",
    "    time=0\n",
    "    logpart_df=pd.Dataframe()\n",
    "    logpart_df.columns= ['time','visited_page']\n",
    "    in_error=1\n",
    "    page =#select a page that follows sourcepage and is not correct page\n",
    "    logpart_df = df.append({'time':time,'visited_page':page})\n",
    "    path_len=1\n",
    "    while in_error:\n",
    "        state=action_probability_in_wrong_path(page, path_len)\n",
    "        if state==\"continueError\":\n",
    "            page= #select a page that connects to the previous page in site map\n",
    "            if page == sourcepage :\n",
    "                in_error=0\n",
    "            logpart_df = df.append({'time':page_time+variation_time,'visited_page':page})\n",
    "        elif state = \"backToCorrect\":\n",
    "            reverse_viseted = logpart_df(visited_page).reverse\n",
    "            for page in reverse_viseted\n",
    "            #reversily add all pages in the logpart_df\n",
    "            \n",
    "            in_error=0\n",
    "            break;\n",
    "        else\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set Initial Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the mean and standard deviation for the number of roles\n",
    "mu_role_number = 10\n",
    "sd_role_number = 3\n",
    "\n",
    "\n",
    "# Set the parameters of gaussian mixture model\n",
    "mu=[2,50,1000]\n",
    "sd=[5,20,500]\n",
    "p=[0.2,0.8,1]\n",
    "\n",
    "# Set the number of tasks\n",
    "mu_n_task=30\n",
    "sd_n_task=10\n",
    "\n",
    "# Set the mu and sd of number of pages in each task\n",
    "mu_pages=7\n",
    "sd_pages=3\n",
    "\n",
    "# Set the starting time \n",
    "pre_time=0\n",
    "\n",
    "#Set number of session for collecting log file\n",
    "n_session=2\n",
    "\n",
    "# Set the mu and sd of number of task performance in each session\n",
    "mu_task_per_session=1\n",
    "sd_task_per_session=2\n",
    "min_task_per_session=0\n",
    "max_task_per_session=20\n",
    "\n",
    "# Set the exponential distribution parameter for determiing the time between entrance of users to the system.\n",
    "lambda_time=2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Random Sitemap, Task Models and Page Names\n",
    "\n",
    "Generate a random sitemap based on number of tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sitemap import SiteMap\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Determine number of tasks\n",
    "n_task= int(np.random.normal(mu_n_task, sd_n_task))\n",
    "if n_task <=0:\n",
    "    n_task=1\n",
    "    \n",
    "# Generate a random site map based on number of tasks and distribution of number of pages in each task\n",
    "sitemap=SiteMap()\n",
    "sitemap.generate_random_sitemap(n_task,mu_pages,sd_pages)\n",
    "\n",
    "# Get the list of all pages in website\n",
    "pageList= sitemap.get_all_pages()\n",
    "\n",
    "# Get total number of pages \n",
    "n_page= sitemap.get_num_pages()\n",
    "\n",
    "# Get the list of pages in each task\n",
    "taskList=sitemap.get_task_list()\n",
    "\n",
    "# Get the usability feature of each page in the web site\n",
    "#web_feature=setup_website_featurs(pageList)\n",
    "#plot_distribution_of_usability_feature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. System's Roles Set up\n",
    "\n",
    "Randomly select the number of roles, the number of users associated with each role, and the activity frequency of each role in the system, with predefined distributions.\n",
    "- select number of role based on mu_role_number and sd_role_number\n",
    "- select number of users per role based on mu_user_number and sd_user_number\n",
    "- select the activity frequency of each role randomly\n",
    "- Determine the distribution of performing each task by each role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "\n",
    "\n",
    "# Generate a random number of roles\n",
    "num_roles = int(np.random.normal(mu_role_number, sd_role_number))\n",
    "if num_roles <=0:\n",
    "    num_roles=1\n",
    "\n",
    "\n",
    "# Generate a random number of users per role based on a gaussian mixture model\n",
    "num_user_in_task=[0]*num_roles\n",
    "for i in range(num_roles):\n",
    "    num_user_in_task[i]=gaussian_mixture_randint(mu,sd,p,True)\n",
    "\n",
    "# Initialize history of usage for each user which include the number of performing each task by each user and the last date of usage\n",
    "n_user=sum(num_user_in_task)\n",
    "task_performance_history = [[(\"\", 0) for _ in range(n_task)] for _ in range(n_user)]\n",
    "visited_page_history = [[(\"\", 0) for _ in range(n_page)] for _ in range(n_user)] \n",
    "\n",
    "# Generate a random activity frequency for each role\n",
    "role_activity_frequencies = random_probablity(num_roles)\n",
    "\n",
    "# Print the results\n",
    "#print(f\"Number of roles: {num_roles}\")\n",
    "#print(f\"Number of users per role: {num_user}\")\n",
    "#print(f\"Activity frequencies: {role_activity_frequencies}\")\n",
    "\n",
    "# Determine the distribution of performing each task by each role\n",
    "task_distribution=[]\n",
    "for i in range(num_roles):\n",
    "    task_distribution.append(random_probablity(n_task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.\tRole,User, Time and Task Configuration\n",
    "Randomly select a role based on its activity frequency in the system.\n",
    "Randomly select a user from the users assigned to the selected role.\n",
    "Randomly select a task for the user, based on the distribution of task performance for the user's role.\n",
    "\n",
    "The Exponential Distribution is the time between events in a Poisson process. Simply, it is an inverse of Poisson. If the number of occurrences follows a Poisson distribution, the lapse of time between these events is distributed exponentially. It is used to model items with a constant failure rate. (the Poisson distribution deals with the number of occurrences in a fixed period of time, and the exponential distribution deals with the time between occurrences of successive events as time flows by continuously.)  The distribution has one parameter, Î» which is assumed to be the average rate of arrivals or occurrences of an event in a given time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id       time visited_page task_id\n",
      "0     860   0.195495   INZDMBEDnV      17\n",
      "1    2578   0.391745   INZDMBEDnV      20\n",
      "2    2578   1.736696   INZDMBEDnV       4\n",
      "3    2578  13.654735   INZDMBEDnV      17\n",
      "4    2578  27.007872   UJVQddTmJF      17\n",
      "5    2578  30.983583   INZDMBEDnV      17\n",
      "6    2578  38.263917   INZDMBEDnV      17\n",
      "7    2578  43.985090   INZDMBEDnV      22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshaf\\AppData\\Local\\Temp\\ipykernel_15400\\882830942.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append({'user_id':selected_userid,'time':action_time,'visited_page':page,'task_id':selected_task}, ignore_index=True)\n",
      "C:\\Users\\sshaf\\AppData\\Local\\Temp\\ipykernel_15400\\882830942.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append({'user_id':selected_userid,'time':action_time,'visited_page':page,'task_id':selected_task}, ignore_index=True)\n",
      "C:\\Users\\sshaf\\AppData\\Local\\Temp\\ipykernel_15400\\882830942.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append({'user_id':selected_userid,'time':action_time,'visited_page':page,'task_id':selected_task}, ignore_index=True)\n",
      "C:\\Users\\sshaf\\AppData\\Local\\Temp\\ipykernel_15400\\882830942.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append({'user_id':selected_userid,'time':action_time,'visited_page':page,'task_id':selected_task}, ignore_index=True)\n",
      "C:\\Users\\sshaf\\AppData\\Local\\Temp\\ipykernel_15400\\882830942.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append({'user_id':selected_userid,'time':action_time,'visited_page':page,'task_id':selected_task}, ignore_index=True)\n",
      "C:\\Users\\sshaf\\AppData\\Local\\Temp\\ipykernel_15400\\882830942.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append({'user_id':selected_userid,'time':action_time,'visited_page':page,'task_id':selected_task}, ignore_index=True)\n",
      "C:\\Users\\sshaf\\AppData\\Local\\Temp\\ipykernel_15400\\882830942.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append({'user_id':selected_userid,'time':action_time,'visited_page':page,'task_id':selected_task}, ignore_index=True)\n",
      "C:\\Users\\sshaf\\AppData\\Local\\Temp\\ipykernel_15400\\882830942.py:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  log_df = log_df.append({'user_id':selected_userid,'time':action_time,'visited_page':page,'task_id':selected_task}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns= ['user_id','time','visited_page','task_id']\n",
    "log_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for se in range(n_session):\n",
    "    #===print(\"session:\",se)\n",
    "    # determine number of task in current session\n",
    "    n_task_in_session= int(truncated_normal_rand(mu_task_per_session,sd_task_per_session,min_task_per_session,max_task_per_session))\n",
    "    \n",
    "    # Generate a random time between arrivals using the exponential distribution\n",
    "    time_between_arrivals = random.expovariate(lambda_time)\n",
    "    start_time=pre_time+time_between_arrivals\n",
    "    pre_time= start_time\n",
    "\n",
    "    # Randomly select a role based on its activity frequency in the system.\n",
    "    selected_role=random_item_selection(role_activity_frequencies)\n",
    "     #print(task_distribution[selected_role])\n",
    "\n",
    "    # Determine user indexes for each role\n",
    "    user_index=[0]*(num_roles+1)\n",
    "    for i in range(num_roles):\n",
    "        user_index[i+1]=user_index[i]+num_user_in_task[i]\n",
    "\n",
    "    # Randomly select a user in detemined role\n",
    "    selected_userid= random.randint(user_index[selected_role],user_index[selected_role+1])\n",
    "    \n",
    "    for t in range(n_task_in_session):\n",
    "        #===print (\"    task:\",t)\n",
    "        # Randomly select a task for the user, based on the distribution of task performance for the user's role\n",
    "        selected_task=random_item_selection(task_distribution[selected_role])\n",
    "        task=taskList[selected_task]\n",
    "        \n",
    "        #Set the time of requesting first page in the current task\n",
    "        action_time=start_time\n",
    "        \n",
    "        i=0\n",
    "        while (i<len(task)):\n",
    "            \n",
    "            # Determine the visited page\n",
    "            page=task[i]\n",
    "            \n",
    "            # Record the user action in log file\n",
    "            log_df = log_df.append({'user_id':selected_userid,'time':action_time,'visited_page':page,'task_id':selected_task}, ignore_index=True)\n",
    "                        \n",
    "            # Determine the probability of user action based on history of usage and page features and number of visited this page\n",
    "            # -- This part later will be replaced by taking a random value from each variable final distribution in the BN\n",
    "            correct_path = truncated_normal_rand(50,30,0,100)\n",
    "            back=truncated_normal_rand(50,30,0,100)\n",
    "            loop=truncated_normal_rand(50,30,0,100)\n",
    "            wrong_path=truncated_normal_rand(50,30,0,100)\n",
    "            incomplete = truncated_normal_rand(50,30,0,100)\n",
    "            time=truncated_normal_rand(3,8,0,20)\n",
    "            \n",
    "            # update next action time and history of visited current page\n",
    "            pageIndex= pageList.index(page)\n",
    "            previous_viseted=visited_page_history[selected_userid][pageIndex][1]\n",
    "            visited_page_history[selected_userid][pageIndex]=(action_time,previous_viseted+1)\n",
    "            action_time+=time\n",
    "            \n",
    "            # This assignment is for readability\n",
    "            CORRECT_PATH=0\n",
    "            BACK=1\n",
    "            LOOP=2\n",
    "            WRONG_PATH=3\n",
    "            INCOMPLETE=4\n",
    "            \n",
    "            # Select users final action\n",
    "            actions=[correct_path,back,loop,wrong_path,incomplete]\n",
    "            sorted_actions_prob = sorted(actions, reverse=True)\n",
    "\n",
    "            # Select the max probability\n",
    "            max_action_prob = sorted_actions_prob[0]\n",
    "            selected_action= actions.index(max_action_prob)\n",
    "            \n",
    "            if selected_action==BACK and i==0:\n",
    "                # Select the Second max\n",
    "                second_max_action_prob = sorted_actions_prob[1]\n",
    "                selected_action= actions.index(second_max_action_prob)\n",
    "            \n",
    "            #===print(\"          page \",page, \" action= \",selected_action)\n",
    "            if selected_action==CORRECT_PATH:\n",
    "                i+=1\n",
    "            elif selected_action==BACK:\n",
    "                i-=1\n",
    "            elif selected_action==LOOP:\n",
    "                pass\n",
    "            elif selected_action==INCOMPLETE:\n",
    "                break;\n",
    "            elif selected_action==WRONG_PATH:\n",
    "                print(\"Wrong patg should be completed\")\n",
    "                #visited_wrong_pages(sitemap,sourcepage,correctpage, user,visited_page_history)\n",
    "      \n",
    "        # update history of task performance        \n",
    "        performance_num=task_performance_history[selected_userid][selected_task][1]\n",
    "        task_performance_history[selected_userid][selected_task]=(start_time,performance_num+1)\n",
    "        start_time=action_time\n",
    "\n",
    "\n",
    "print(log_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Determine the value of Bayesian Nodes\n",
    "Feed the user and page information into the Bayesian network to determine the next move of the user\n",
    "\n",
    "we will replace this part by randomly assign a value to the final nodes in the Bayesian network. these values later will be determined by BN. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['udyniCVRqg', 'agjHkQfebU', 'zws5KMibK5', 'bNohKDB3ba', 'UoWcPuIwPE', '0D3jR6OCPG', '106E654UYE', 'ls5T596tvo']\n",
      "['udyniCVRqg', 'ElGelSuyr3', 'FNV8nWxmt1', '6umKDMhijS', 'TYQabuFYFb', 'qq1RPqNSYy', 'X0M0ZClEkE', 'O2paKUXFLh', 'phX8yGbZMJ']\n"
     ]
    }
   ],
   "source": [
    "print(taskList[3])\n",
    "print(taskList[30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Dataframe:\n",
    "- Add each row to the dataframe\n",
    "- Sort by time\n",
    "- replace user id by ip\n",
    "- replace page name with URLs\n",
    "- write into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
